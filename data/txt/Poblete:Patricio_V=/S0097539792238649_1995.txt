SIAM J. COMPUT.
Vol. 24, No. 2, pp. 266-278, April 1995

() 1995 Society for Industrial and Applied Mathematics
OO6

PERMUTING IN PLACE*

FAITH E. FICHt, J. IAN MUNROt, AriD PATRICIO V. POBLETE

Abstract. This paper addresses the fundamental problem of permuting the elements of an array of n elements
according to some given permutation. It aims to perform the permutation quickly by using only a polylogarithmic
number of bits of extra storage. The main result is an algorithm whose worst case running time is O (n log n) and
uses O (log n) additional log n-bit words of memory. A simpler method is presented for the case in which both the
permutation and its inverse can be computed at (amortised) unit cost. This algorithm requires O(n log n) time and
O (1) words in the worst case. These results are extended to the situation in which a power of the permutation must
be applied. A linear time, O (1) word method is presented for the special case in which the data values are all distinct
and are either initially in sorted order or will be when permuted.

Key words, permutation, reordering, space, in place

AMS subject classifications. 68P05, 68P 10

n}--

1. Introduction. Given an array A[1..n] and a permutation :r

n},
we wish to rearrange the elements of the array in place according to the permutation. More
precisely, the rearrangement consists of performing the equivalent of the n simultaneous
assignments

A[rr(i)]-- A[i] for/ 6 {1

n}.

Thus if the array A originally contains the sequence of values a, a2
it contains the sequence a-,(), ar-(2)

ar-(n).

an, then, afterwards,

"In place" means that the algorithm performs the rearrangement by repeatedly interchanging 
pairs of elements. Hence, the set of values in the array and the number of times each occurs
always remain the same. In particular, this definition precludes moving the elements into an
auxiliary array and then putting each element, one at a time, into its correct location in the
original array. It also means that the array cannot be padded with blanks (see, for example,
[7]) to make it a more convenient size to work with.

The problem of rearranging data arises in a variety of situations. Some examples are transposing 
a rectangular matrix [12, Ex. 1.3.3-12], [7], rotating a bit map image, and exchanging
two sections of an array [2, p. 134].

In sorting a list with very large records, it might be more efficient to manipulate pointers
to the records rather than the records themselves and, afterwards, put each record into its
appropriate location [13, p. 74]. Another way to sort [13, p. 76] is to first compare every pair
of keys, then, for each record, count the number of other records that should precede it and
rearrange the records accordingly.

In certain circumstances, searching is not most efficient when the elements of the array
If a large number of searches are going to be performed, it could be
are in sorted order.
advantageous to rearrange a sorted array first. For example, one can simplify the index
computation in a binary search by organizing the elements into a data structure that implicitly
represents a complete binary search tree (via a breadth first, left to right, enumeration of its
nodes) 1, Ex. 12-6, pp. 136, 183-184], 13, Ex. 6.2.1-24, pp. 422, 670], 12, p. 401 ]. Like a

*Received by the editors October 13, 1992; accepted for publication June 10, 1993. This research was supported
in part by the Natural Science and Engineering Research Council of Canada under grant numbers A-8237 and A-9176,
the Information Technology Research Centre of Ontario, and the Chilean FONDECYT under grant numbers 901263

and 91 1252.

Department of Computer Science, University of Toronto, Toronto, Ontario, Canada M5S 1A4.
;Department of Computer Science, University of Waterloo, Waterloo, Ontario, Canada N2L 3G 1.
Departamento de Ciencias de la Computaci6n, Universidad de Chile, Casilla 2777, Santiago, Chile.

266

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpPERMUTING IN PLACE

267

heap, an element in location < n/2 has its left and right children in locations 2i and 2i / l,
respectively. When the data is stored on a disk with each block capable ofholding b elements or
in a virtual memory in which each page can contain b elements 13, pp. 472-473], the number
of reads can be minimized by arranging the elements using a similar implicit representation
of a complete (b + 1)-ary search tree [12, p. 401]. These three different arrangements are
illustrated in Fig. 1. In the third case, b

3.

FIG. 1. Three arrangements of a list of length 15.

We are interested in the amount of time and additional space needed to rearrange the
elements of the array according to the input permutation. Previously known algorithms for
this problem used either quadratic time or a linear amount of additional space in the worst
case. In this paper, we present a concise algorithm that takes time O(n log n) and uses only
O (log2 n) bits of additional storage. We have a simpler method for the case in which both the
permutation and its inverse are given; it takes the same amount of time and uses only O(log n)
bits. Furthermore, we show how to use the fact that a permutation is known to rearrange the
array either to or from sorted order to obtain an algorithm that takes time O(n) and uses only
O (log n) bits of additional storage.

Throughout the paper, we assume that the permutation Jr is given by means of an oracle.
This models the situation where the value of Jr(i) is computed from
(e.g., transposing a
rectangular array) or the permutation cannot be changed (e.g., because it is being used by
other processes). If the permutation is given by an array and its entries can be used to record
information as the algorithm proceeds (perhaps destroying the permutation in the process),
data rearrangement can be done efficiently by using O (n) time and O (log n) additional bits
of storage [13, Ex. 5.2-10, pp. 80, 595]. This is also the case when the permutation is given
as a product of disjoint cycles.

2. Cycle leader algorithms. The cycle structure of the permutation can be exploited to
obtain efficient algorithms for rearranging data. Permutations are composed of one or more
disjoint cycles, as illustrated in Fig. 2. The arrows follow the direction
Jr(i), indicating
the direction in which the data should flow.

Jr(i)

3

2
9

3
4

4
2

5

6
6

8

10
7
8 7 5 10

9

2

5

6 ’9 10

FIG. 2. A graphical representation of a permutation.

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php268

FAITH E. FICH, J. IAN MUNRO, AND PATRICIO V. POBLETE

A basic operation is ROTATE (see Fig. 3) which, starting from some designated location
in a cycle, moves the values from one location of the cycle to the next. We call this designated
location the cycle leader. For example, the cycle leader could be the smallest location in the
cycle. Once the cycle leader has been identified, ROTATE can be performed by proceeding
through the cycle, starting with its cycle leader and exchanging the value located at the cycle
leader with the values in the successive locations of the cycle. Each of these other values is
involved in exactly one exchange (that takes it to its correct final location). Thus the time
taken by such an algorithm is proportional to n, the length of the array, plus the amount of
time it takes to find all the cycle leaders.

procedure ROTATE(leader)

+- re(leader)

interchange the values in A[leader] and A[i]

while/

leader do

+- re(i)

FIG. 3. Rotating the values in a cycle.

If the permutation re is given as a product of disjoint cycles, identifying a leader for each
cycle is very straightforward: merely take the first element in each cycle. The problem is
n. One way to find
more interesting when re is given as a mapping from the elements
all the cycle leaders in this case is to consider the locations
n one at at time and, for
each, determine whether it is a cycle leader.

If an additional, initially empty, bit vector of length n is available, it is easy to determine
whether a location is the smallest element in its cycle in constant time. Specifically, when the
value in an array location is moved, the bit corresponding to that location is set to 1. Since the
locations are considered from smallest to largest, a location under consideration will have its
corresponding bit equal to 0 exactly when it is a cycle leader [12, Ex. 1.3.3-12(b), pp. 180,
517-518]. Similarly, if re is given as an array whose elements can be modified, the same effect
can be achieved by setting rr(i) to when the value in array location

is moved.

Determining whether or not a location is the smallest element in its cycle can also be
accomplished by using only a constant number of pointers into the array (each log2 n bits
Specifically, starting at the given location, proceed along the cycle until either the
long).
entire cycle has been traversed or a smaller location is encountered. In the first case, the
given location is a cycle leader; otherwise it is not. The total amount of time to consider
all n locations is O(n2). The worst case is achieved when re
(1 2 3... n). For random
permutations, an average of O(n logn) steps are performed [11], [13, p. 595].
These two ideas can be combined into the algorithm illustrated in Fig. 4.
THEOREM 2.1. In the worst case, permuting an array of length n, given the permutation,
can be done in O(nZ/b) time and b + O(logn) bits of auxiliary space (consisting of a bit
vector of length b plus a constant number ofpointers) for b < n.

The array A is conceptually divided into [n/bq regions. Each region has size b, except for
the last region, which might be smaller. The bit vector V is used to keep track of which locations
in the region are encountered as the region is processed. If the location under consideration
for being a cycle leader has a corresponding bit with value 0, its cycle is traversed until a
smaller location is encountered. If no smaller location is encountered, then the location is a
cycle leader and the cycle is rotated. Furthermore, if the location under consideration has a
corresponding bit with value 1, then the location was previously encountered as part of a cycle
containing some smaller location in the region and, hence, it is not a cycle leader. Theorem 2.1
follows from these observations.

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpPERMUTING IN PLACE

269

for k +--

to In do
s +- (k
if k <_ Ln/bJ then
else
to do

1)b

for

g[i]-- 0

if V[i]

fori +-- ltoldo

--

+- b
+- n

bLn/bJ

0 then Vii] +--

j <-- Jr(s + i)
whilej >s+ido

ifj <s+lthenV[j-s] <--
j +-- Jr(j)

s + then ROTATE(s + i)

if j

FG. 4. Rearranging an array using a bit vector V of length b.

If both Jr and Jrare 
available, then it is possible to get a more efficient algorithm.
Determining whether or not a given location is the smallest element in its cycle can be done
by starting at the location and proceeding alternatively forwards and backwards along the
cycle until either the entire cycle has been traversed or a smaller location is encountered. (See
Fig. 5.)

for/ 6 {1

n} do

j +- Jr(i)

if j # then kJr


(i)

whilei <jandi <kdo

if j

k then ROTATE(i)

j <-- Jr(j)
if j

k then ROTATE(i)

exit

exit

k +- Jr-l (k)

FIG. 5. Rearranging an array using a permutation and its inverse.

THEOREM 2.2. In the worst case, permuting an array of length n, given the permutation

and its inverse, can be done in O(n log n) time and O(log n) additional bits of storage.

The analysis is similar to the bidirectional distributed algorithm for finding the smallest
element in a ring of processors [8]. Specifically, the algorithm cannot determine whether is
a cycle leader after proceeding steps forwards and steps backwards along the cycle starting
from i, only if the
in its cycle are all
larger than t. Furthermore, this will be the case for at most /t of the choices for i.

It is interesting to compare this algorithm to the O(n2) time O(logn) space algorithm
mentioned above. Their expected behaviour on a random permutation is identical. However,
the algorithm in Fig. 5 eliminates the bad cases.

elements preceding

elements following

and the

It is not necessary that the cycle leader be the smallest (or largest) location in the cycle.
One approach is to apply a hash function to the elements of the permutation and take as cycle
leader the location in the cycle that hashes to the smallest value. Starting at a given location, the
algorithm proceeds along the cycle until either the entire cycle has been traversed or another
location that hashes to a smaller value is encountered. If the hash function is randomly chosen
from among a set of 5-wise independent hash functions, then this results in a randomized
algorithm using O(log n) space and expected time O(n log n) for every input permutation [9].
It was not clear to us whether or not it was possible to have a deterministic algorithm that
used n log () n time and log (t) n space without having the inverse permutation available.
However, using a rather different approach, we were able to devise such an algorithm.

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php270

FAITH E. FICH, J. IAN MUNRO, AND PATRICIO V. POBLETE

THEOREM 2.3. In the worst case, permuting an array of length n, given the permutation,

can be done in 0 (n log n) time and 0 (log2 n) additional bits of storage.

{i E Er_

Jrr-ll(i) >

{1

n} and Jrl

First, consider the following characterization of the minimum locations in the cycles of
the permutation Jr. Let E
Jr. For r > 1, we inductively define
Er C_ Er_ to be the set of local minima encountered following the permutation Jrr-, that
is, Er
Er --+ Er to be
the permutation that maps each element of Er to the next element of Er that is encountered
following the permutation Jrr-1. In other words, if
min{m > 0
We call Er the set of order r elbows.

Jr(i), where M min{M > 0

< Jrr-l(i)}. We also define Jrr

Jrrm_l(i) 6 Er}, and Jrr(i)

Jrrm_l (i), where m

Jr4(i) 6 Er}.

Er, then Jrr(i)

For example, if Jr

(1 5 3 610 4 29 87 11), as illustrated in Fig. 6, then

El ={1,2,3,4,5,6,7,8,9,10,11},
E2
E3
E4

l, 2, 3, 7},
{1,2},

}, and

Jr =(1536104298711),
7/"2
Jr3
Jr4

(1 3 27),
(! 2),
(1).

11

9

8

7

Jr2

7/"

10

4

5

3

FIG. 6. A cycle and its elbows.

No more than half the elements in any cycle are local minima. Thus IErl < IEr-I I/2.
The minimum element of a cycle of Jr is always in Er if the cycle contains more than one
element of Er-l. Hence the minimum element in a cycle is the unique elbow of maximum
order in its cycle.

Computing the sets of elbows El, E2

and the corresponding permutations Jr, 7/"2

The unidirectional nature of our oracle means that given

can be done either in a top-down fashion, analogous to recursive descent parsing, or bottomup,
 analogous to shift-reduce parsing. We explore both approaches in the two algorithms that
follow.

Jrr(i) but difficult to compute Jrr- (i). Thus determining whether is a local minimum of Jrr

Er+l) is difficult starting from i, but easy starting from i’s predecessor
(i.e., whether or not
in Jrr. For example, in Fig. 6, starting from 5 we can recognize that its successor, 3, is a local
minimum in Jr. In turn, starting from 3 we can recognize that 2, its successor in Jr2, is a local
minimum in Jr2.

6 Er, it is easy to compute

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpPERMUTING IN PLACE

271

For each cycle, the algorithm in Fig. 7 chooses the leader to be the unique element

in
Jr (i) 6 E,,., where s is the maximum order of any element in the
the cycle such that Jr,,._
cycle. In other words, an element can be rejected as soon as it is seen not to be the element of
maximum order. Dolev, Klawe, and Rodeh [4] and Peterson [14] independently discovered
the usefulness of this choice of cycle leader for electing a leader in a unidirectional ring of
processors using O (n log n) messages.

The procedure call NEXT(r) is used to compute successive elements of Jrr. It does this

recursively, using successive elements of Jrr-1.

6

For each

n}, the main program tests whether or not Jr (i) 6 E2 by comparing
Jrl (i) with and Jrljr (i); if so, it next tests whether ornot JrZjrl (i) G E3 by comparing JrZjrl (i)
with Jr (i) and Jr2jrZjrl (i), etc. One test is performed each iteration of the inner for loop.
Er+.
Eventually, a value of r is found such that Jrr-I... Jrl (i) 6 Er but Jrrjrr-1... Jr (i)
There are three possible ways this can occur. One is when Jrrjrr-1-.- Jr (i)
Jr (i).
Jrr-I
Then, since Jrr is a permutation, this implies that the cycle of Jrr that contains JrrJr 
(i)
Jrl (i) is the minimum element in the cycle of Jr that contains it. In
is trivial and thus Jrris 
a cycle leader. The other possible situations are when either Jrr-1-.-Jr (i) <
this case,
Jr (i) > Jrrjrrjrr-1 ..-Jrl (i). In both these cases, the algorithm
Jrl (i) or Jrrjrr-
Jrrjrr-I
detects that Jrrjr-.-. Jr (i) is not the minimum element in its cycle and thus that
is not a
cycle leader.

Using O(log2 n) space, very little information about each permutation can be stored. We
show that, essentially, only the most recently detected elbow of each order need be stored.
The algorithm in Fig. 7 stores this information in the array elbow. For r > 1, elbow[r] is
used to store an element of Er. Immediately prior to a call to NEXT(r), the elements satisfy
the condition

and immediately afterwards, they satisfy the condition

7rl

7rr-I

elbow[r]

elbow[r- 1] -+ ...--+ elbow[O]

elbow[r]- elbow[r- 1] --+ ...-+ elbow[O].

elbow[r] and elbow[r

2]

7rr_

The procedure NEXT(r) computes Jrr (elbow[r]). This leaves elbow[r] unchanged and places
the result in elbow[r

1] (and, of course, updates the earlier elements in the array).

1] (and elbow[r

Jrr- (elbow[r]); thus elbow[r

2]. The first while loop in NEXT(r) advances elbow[r

If r > 1, NEXT(r) recursively computes successive elements along Jrr_l, starting from
Er, elbow[r] < Jr-I (elbow[r]).
<

elbow[O], recursively) as long as Jrris 
strictly increasing. The cycle of Jrr- con-
1] >

elbow[r], until a local minimum is detected. Since elbow[r]
Initially, elbow[r
elbow[r
2]
taining elbow[r] is not trivial; thus, when the first while loop terminates, elbow[r
elbow[r-2]
(and elbow[r
end of the second while loop, elbow[r
elbow[rJr_ 
(elbow[r- ]). The second while loop continues advancing elbow[r-
2]

Jr m (j), then Jr L (j)_ Er for < L < M.

elbow[O], recursively) as long as Jrr-1 is strictly decreasing. At the
]). Hence
Jr,(elbow[r]).
Er+. At the beginning of the rth iteration
Er.
Jr;-(i’) and
Jrr(i’). Furthermore, elbow[O]
]). It is easy to prove by induction on r that if j 6 E and M is the

’ E+, either elbow[r]

of the inner for loop of the main program, elbow[r]
When the computation detects
elbow[r- 1]

smallest positive integer such that Jr
Thus, starting from i’ and proceeding along Jr, the element Jr

is the next local minimum ofjrr_l. In other words, elbow[rthat

i’ and elbow[r- 1]

Jrrjr-l...jrl(i) G Er

Jrr-ljrr(i’) will be reached

Jrr- (elbow[r

Jrr-1 (elbow[r

i’ or elbow[r]

< elbow[r

2]

Jrr-...jrl(i)

Jr-(i’)

i’

Jrr-1 (j)

Suppose i’

Jrl

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php272

FAITH E. FICH, J. IAN MUNRO, AND PATRICIO V. POBLETE

procedure NEXT(r)
ifr

1] < elbow[r

2] do

elbow[r- 1] +-elbow[r- 2]
NEXT(r- 1)

while elbow[r- 1] > elbow[r- 2] do

elbow[r- 1] -elbow[r- 2]
NEXT(r

1)

else while elbow[r

then elbow[O]-- 7r(elbow[1])
elbow[O]-- elbow[l] +--

forr +- 1,2

n}do

do

return

fori 6{1

{loop invariant: elbow[r]
NEXT(r)
if elbow[r] > elbow[r- 1]
then elbow[r] +-- elbow[r

1]

7rr_

7rzZrl(i) G Er}

NEXT(r)
if elbow[r] > elbow[r- 1] then exit
elbow[r + 1] +-- elbow[r]
if elbow[r]
exit

elbow[r

1] then ROTATE(i)

else

FIG. 7. A recursive algorithm that rearranges an array using O(n log n) time and O(log n) space.

2(i,).

-1

Similarly, starting from i’ and proceeding backwards along 7r, the element
before
Zrr-_lrr-i (i’) will be reached before 7rr-2(i’). Therefore, testing whether or not
--Tr
is a cycle leader involves proceeding along 7r in a subsegment of the region between 7rr-2(i ’)
and 7rr2 (i’).

Er+, the permutation 7r is evaluated less than 4n times. (In
fact, 7r is evaluated at most 4 times at each element.) Since Er is empty for r > log2 n, the
algorithm proceeds a total of O(n log n) steps along

Considering all i’

E,.

Each call of NEXT(I) proceeds one step along 7r. Each call of NEXT(r), for r > 1,
1). The total amount of work performed by
involves at least two recursive calls to NEXT(r
this call (excluding the work performed by the recursive calls) is proportional to the number
of recursive calls it makes. For each i, every iteration of the inner for loop performs a constant
amount of work (excluding the work performed by the subroutines it calls) and, except for
possibly the last iteration, involves two calls to NEXT. Thus the total amount of work performed
by the entire algorithm is proportional to the total number of steps the algorithm proceeds along
7r plus O (n) steps to rotate all the cycles.

When zr consists of a single cycle with the elements {0

1} ordered lexicographically 
with respect to the reverse of their (log n)-bit binary representations (for example,
5 3 7)), the algorithm actually uses f2(n logn) steps. Hence the running time
:r
of the algorithm is in (R)(n log n).

(0 4 2 6

n

The algorithm uses (R)(log n) variables, each capable of holding one element in

n}.
With care in implementation, only O (log n) bits are needed for representing the program stack.
Thus a total of (R)(log2 n) bits of additional space are used by this algorithm.

An iterative, bottom-up version of the algorithm in Fig. 7 is given in Fig. 8. As elbow[O]
is advanced along the cycle of 7r containing i, elbow[r], for r > 1, records the most recent
element of E that has been detected. Each time a local minimum along rr_l is detected,
elbow[r] is advanced to that location. The variable state[r] encodes information about the
portion of the cycle of 7r that is being examined.

The first time an element of E is detected, state[r] is set to GOT_ONE and elbow[r]

7/’r-1 1 (i). When the next element of Er (along zrr) is detected, the algorithm can determine

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpPERMUTING IN PLACE

273

for/ 6 {1

n} do

elbow[1 +-
state[
repeat

+- GOT__ONE

r+-I
elbow[O] +- :r(elbow[1])
while state[r] =DOWN and elbow[r] < elbow[r

1] do

state[r] +-UP
elbow[r] +- elbow[r- 1]
r+-r+l

case state[r]

GOT_ONE: if elbow[r] > elbow[r- l]

then

else

state[r] +- GOT_TWO
elbow[r] +- elbow[r- 1]
if elbow[r]
exit

elbow[r

1] then ROTATE(i)

GOT_TWO: if elbow[r] > elbow[r

1] then exit

state[r + l] +- GOT__ONE
elbow[r + 1] +- elbow[r]
state[r] +- UP
elbow[r] +- elbow[r- 1]

UP:

if elbow[r] > elbow[r- l] then state[r] +- DOWN
elbow[r] +- elbow[r- 1]

DOWN:

elbow[r] +- elbow[r- 1]

FI. 8. An iterative algorithm that rearranges an array using O(n log n) time and O(log n) space.

If state[r]

whether i’s cycle contains only one element in E. If so,
the algorithm sets state[r] to GOT__TWO and tries to determine whether ornot 7rTr_
is a local minimum of 7r (and hence an element of Er+,).

is the leader of its cycle. Otherwise
:r (i)
UP, then elbow[r] is known to be larger than r’ (elbow[r]), which is its
DOWN, then elbow[r] is known to be smaller

than 7r- (elbow[r]), which is its predecessor along 7r. This information is sufficient to detect

successive local minima along 7r. Figure 9 illustrates the states that occur as the algorithm
proceeds along a cycle.

predecessor along 7r. Similarly, if state[r]

I GOT_TWO

GOT ONE

UP

DOWN

UP

FI6. 9. The states occurring in the iterative algorithm.

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php274

FAITH E. FICH, J. IAN MUNRO, AND PATRICIO V. POBLETE

procedure ROTATE BACKWARDS(leader)
j +- leader

+- re(leader)

while

leader do

interchange the values in A[j] and A[i]
j+-i

+- zr(i)

FIG. 10. Rotating the values backwards in a cycle.

procedure EXCHANGE(i, j, m)
repeat m times

interchange the values in A[j] and A[i]

+- re(i)
j +- re(j)

procedure ROTATE(q, leader, cyclelength)
irun +- q mod cyclelength
jrun +- cyclelength
irun

+- leader
j +- leader
repeat irun times
j +- re[j]

while irun # jrun do
ifirun < jrun

then temp--
empelse


+- temp

EXCHANGE(i, j, irun)

EXCHANGE(i, j, irun)

jrun +- jrun

irun

EXCHANGE(i, j, jrun)
j +- temp
irun <-- irun

jrun

Fie. 11. Rotating the values q steps in a cycle.

A small but natural twist on our problem is that we are given rr, but required to move
the elements according to re-. The cycle leader technique of Theorem 2.3 is still applicable.
It is only necessary to replace ROTATE by the procedure ROTATE BACKWARDS given in
Fig. 10.

Clearly this step requires time linear in the size of the cycle, and O(log n) bits of memory.
The problem is easily generalized to being given re (and perhaps re-l) and asked to apply
rrq, where q may depend on the (length of the) cycle. Either one of the cycle leader methods
is applicable. We need only define a modified procedure ROTATE(q, leader, cyclelength).
This is essentially the same problem as transposing an array. The following is a translation
into our terms of the method discussed in [2, p. 134]. Suppose that the m elements along re
are distinct from the m elements along re starting at location j. Then the
starting at location
procedure EXCHANGE(i, j, m) exchanges these two sequences of elements. Both and j are
advanced m locations along the cycle as a result of an execution of the procedure EXCHANGE
in Fig. 11.

We see that, including calls to re, the ROTATE algorithm requires time proportional to the

length of the cycle in question; hence we can strengthen Theorems 2.2 and 2.3.

COROLLARY 2.4. In the worst case, permuting an array of length n according to the permutation 
req, given re and its inverse, can be done in O(n log n) time and O(log n) additional
bits of storage.

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpPERMUTING IN PLACE

275

COROLLARY 2.5. In the worst case, permuting an array of length n according to the
permutation req, given the permutation re, can be done in O(n log n) time and O(log2 n)
additional bits of storage.

3. Permuting data in and out of order. In many situations, it is known that the array
elements satisfy a fixed total order, i.e., when the data values are taken in a particular order,
they form a sorted sequence. Suppose the array A has been rearranged according to the
permutation re and let r be a permutation such that
A[cr -l(1)] < A[a -(2)] <

< a[a -(n)].

n. In particular, if or(i) >
Then element A[i] has the cr(i)th smallest value, for
or(re(i)) then A[i] > A[re(i)]. For example, if the permutation re rearranges the array A into
sorted order, then a is the identity permutation and if A was sorted before the rearrangement,
then a

re1.


Consider the rearrangement algorithm in Fig. 12.

In particular, if the permutation re
rearranges the array A into sorted order, then the algorithm is simply looking for places where
the permutation wants to move an element to a lower numbered location and the element is
smaller than the element that is currently there.

for/ E {1

n}do

if (or(i) > a(re(i))) and (A[i] < A[re(i)])

then ROTATE(i)

FIG. 12. Rearranging an array ofdistinct elements that satisfy a fixed total order.

Notice that after the cycle containing location has been rotated, or(i) > r (re(i)) implies

A[i] > A[re(i)]. Thus each nontrivial cycle is rotated at most once.

E

A[re(i)] for all

-7/: re(i) implies A[i]

Now suppose that no two consecutive elements along any nontrivial cycle have the same
n}. This condition is certainly
value, i.e.,
true if the elements of the array A are distinct. We claim that before a given nontrivial
in that cycle such that
cycle of the permutation re has been rotated, there is a location
or(i) > or(re(i)) and A[i] < A[re(i)]. This implies that the cycle will be rotated at least once.
be any location in the cycle that satisfies a(i) > or(re(i)) < o-(re2(i)). (This will be
Let
the case, for example, when re(i) is the location containing the smallest value in the cycle.)
The cycle leader will be the first such location encountered. After the cycle has been rotated,
A[re(i)] _< A[re2(i)], since r(re(i)) < cr(re2(i)). Also, the values in locations re(i) and re2(i)
were initially in locations and re(i), respectively. Hence, before the rotation, A[i] <_ A[re(i)].
However, A[i]

A[re(i)], so A[i] < A[re(i)], as required.

It is not necessary to rotate a cycle if all the elements it contains have the same value.
However, there are other situations where a nontrivial cycle contains consecutive elements
with the same value and the algorithm in Fig. 12 does not rotate the cycle. The example in
Fig. 13 is constructed using two distinct values, o and/, where c < ft. It assumes the array
is to be rearranged into sorted order. Except for the two middle elements, the array is already
sorted, but since these two elements can be arbitrarily far apart in the cycle, no local test (such
as the one in the algorithm in Fig. 12) can succeed in detecting them.

Notice that a cycle containing runs of equal-valued elements has the same effect as the
cycle taking the beginning of each run to the beginning of the next run. Since no consecutive
elements of this latter cycle have the same value, the technique used by the algorithm in
Fig. 12 can be applied to identify a cycle leader.

If the functions re and are can be evaluated in constant time (which is the case when re
rearranges the array either into or out of sorted order), then the algorithm in Fig. 14 runs in

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php276

FAITH E. FICH, J. IAN MUNRO, AND PATRICIO V. POBLETE

FIG. 13. An example with runs of equal-valued elements.

linear time. This is because the algorithm goes through the while loop at most once for each
run of equal-valued elements in a cycle. In fact, the linear time bound holds also under a
weaker assumption.

fori 6 {1

if a[i]

n}do

a[re(i)] then

j +-- re(i)
while a[j]
if (r(re(i)) > r(re(j))) and (a[re(i)] < a[re(j)]) then ROTATE(i)

a[re(j)] do j +- re(j)

FIG. 14. Rearranging any array of elements that satisfy afixed total order.

THEOREM 3.1. Suppose that after the array A is permuted according to the permutation re,
re(n),
cr re (n) can be computed in time 0 (n), then A can be permuted according to re by

it satisfies A[o--l(1)] < A[o--l(2)] <
r re (1)
using O(n) time and O(log n) additional bits of storage, in the worst case.

< A[o--l(n)]. Ifall the elements re(l)

The proof follows from the observation that, for each element i, re(i) and rre(i) are
computed only a constant number of times during the course of the algorithm in Fig. 14. The
running time of this algorithm is clearly dominated by the time spent performing these function
evaluations.

The application that sparked our interest in the problem of rearranging data was building
a data structure implicitly representing a complete binary search tree, given a sorted array of
appropriate length n. Here the median is the root and is placed in location 1. Its children, the
first and third quartiles, are in locations 2 and 3, respectively. In general, the left and right
children of the element in location j are in locations 2j and 2j +
(like a heap). Bentley
anticipates the result shown here in crediting Mahaney and Munro with a linear algorithm
for this special case. In this case, the permutation re satisfies the property that if x 10 is the
log2 n]-bit binary representation of i, then 0 lx is the [log2 nq-bit binary representation of
7r(i).

_< r < 2h, the sorted array can be rearranged to implicitly
represent a binary search tree which is complete except for its last level and such that the nodes
in the last level are as far left as possible. One method is to apply two permutations to the
array. The first permutation re’ moves the r values 1,3, 5
that belong in the last
level of the tree to their correct locations at the end of the array, while keeping the other values
in sorted order. Specifically,

+ r, where

When n

2h

2r

re’(i)

2h+(i-1)/2 if
i/2
if
if > 2r.
ir


is odd and <2r,
is even and < 2r,

The second permutation then rearranges the first 2h
elements of the array into the implicit
representation of a complete binary search tree, as above. Another method is to combine these
two permutations into one, defining re as follows.

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpPERMUTING IN PLACE

277

if

is odd and <2r
then 7r(i)
else re(i) is the number represented by 0 lx,

2h + (i

1)/2

where x 10 is the h-bit binary representation of

i/2,

r,

is even and < 2r,

if
if > 2r.

For most instruction sets, computing re once could take as much as O (log n) steps in the
worst case. However, using only left and right shifts of distance one and single bit assignments
n}. As mentioned above,
and tests, O(n) operations suffice to evaluate re(i) for all
this is sufficient to obtain a linear time algorithm.

E

4. Conclusions. Since most permutations fix very few of their elements, any algorithm
must take f2 (n) time on average and, hence, in the worst case. Also, f2 (log n) additional bits
of storage are needed to provide pointers to array elements that are being interchanged.

The open question that remains is whether there are better algorithms for rearranging
an array given an arbitrary permutation re (and also possibly re-l).
Specifically, are there
algorithms that use a small amount of additional space (e.g., O(log n) or log 1) n) and only
linear time? If not, are there deterministic algorithms that, given only re, run in O (n log n)
time but use only O(log n) bits of additional storage?

When b

n/ log log n, the algorithm in Fig. 4 uses O (n log log n) time and O (n/ log log n)
bits of additional storage. However, it is not even known whether there is an algorithm that
uses o(n log n) time and O(n -) space for some constant > 0.

All of the algorithms presented in this paper are cycle leader algorithms. They proceed by
identifying exactly one element in each cycle and rotating the cycle starting from that element.
Performing all the rotations requires only linear time and two pointers. This leaves the problem
of finding a leader for each cycle, or equivalently, finding the minimum element in each cycle.
Cook and McKenzie [3] have shown that these problems and, more generally, computing the
disjoint cycle representation of a permutation are NC 1-complete for deterministic logspace.
A previous version of the algorithm in Fig. 7 was interesting from the point of view that
it did not operate by determining cycle leaders. Instead, it performed sweeps up and down the
array, at each point deciding whether or not to interchange that element with another element
and, if so, which one. It would be interesting to know if any algorithm for permuting an array
can be transformed into a cycle leader algorithm. This would allow us to restrict attention to
cycle leader algorithms when searching for new algorithms or trying to prove better tradeoffs.
The algorithms in Figs. 5, 7, and 8 and the O(n2) time, O(log n) space algorithm discussed
before Fig. 4 can all be viewed as instances of a restricted type of cycle leader algorithm.
n} to see if it is a cycle leader by
Specifically, they separately test each element
comparing elements forwards and/or backwards along the cycle. The tests depend only on the
permutation re and the values of i. They do not depend on the order in which the elements are
tested, as is the case for the algorithm in Fig. 4 (when b > 1) and the algorithm in Fig. 14, nor
on the data values stored in the array, as is the case for the algorithm in Fig. 14.

E

tests whether element

Such algorithms are interesting because they immediately lead to distributed algorithms,
using only comparisons of ID’s, for electing a leader in a bidirectional ring of synchronous
processors. Processor
is the leader of its cycle once it has learned
the ID’s of a sufficient number of its successors and predecessors. It requests these ID’s by
sending messages forwards and backwards around the ring for distances which are successive
powers of 2. (See [8].) The total number of messages sent is proportional to the time taken by
the cycle leader algorithm. Frederickson and Lynch [5] hava shown that any such distributed
leader election algorithm sends f2 (n log n) messages in the worst case. Thus these restricted
types of cycle leader algorithms must use at least f2 (n log n) time in the worst case. On the
other hand, it is not clear how algorithms for electing a leader in a ring of processors can be

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php278

FAITH E. FICH, J. IAN MUNRO, AND PATRICIO V. POBLETE

used to obtain cycle leader algorithms. The major problems seem to be how to deal with the
timing of messages and how to represent the states of all the processors using less than a linear
amount of space.

REFERENCES

[1] J.L. BENrIE, Programming Pearls, Addison-Wesley, Reading, Mass., 1986.
[2] G. BRASSARD AND 19. BRATLEY, Algorithmics, Prentice-Hall, Englewood Cliffs, New Jersey, 1988.
[3]

S. COOK AND P. MCKENZIE, Problems complete for deterministic logarithmic space, J. Algorithms, 8 (1987),

pp. 385-394.

[4] D. DOLEV, M. KLAWE, AND M. RODEH, O(//log n) unidirectional distributed algorithmfor extremafinding in a

circle, J. Algorithms, 3 (1982), pp. 245-260.

[5] G.N. FREDERICKSON AND N. A. LYNCH, The impact ofsynchronous communication on the problem ofelecting a
leader in a ring, in Proc. 16th ACM Symposium on Theory of Computing, ACM Press, New York, 1984,
pp. 493-505.

[6] R.G. GALLAGER, P. A. HUMBLET, AND P. M. SPIRA, A distributed algorithmfor minimum-weight spanning trees,

ACM Trans. Prog. Lang. Sys., 5 (1983), pp. 66-77.

[7] G.C. GOLDBOGEN, PRIM: A fast matrix transpose method, IEEE Trans. Soft. Eng., SE-7 (1981), pp. 255-257.
[8] D. S. HIRSCHBERG AND J. B. SINCLAIR, Decentralized extrema-finding in circular configurations ofprocesses,

Communications of the Association for Computing Machinery, 23 (1980), pp. 627-628.

[9] R. IMPAGLIAZZO, private communication.
[10] W.W. KIRCHHERR, Transposition ofan

Inform. Process. Lett., 28 (1988), pp. 55-59.

matrix requires S2 (log l) reversals on conservative turing machines,

[11] D.E. KNtrr, Mathematical Analysis ofAlgorithms, Proc. IFIP Congress,
12]

The Art of Computer Programming, Vol. 1: Fundamental Algorithms, Addison-Wesley, Reading, MA,

(1971), pp. 19-27.

1973.

[13]

The Art of Computer Programming, Vol. 3: Sorting and Searching, Addison-Wesley, Reading, MA,

1973.

[14] G.L. PETERSON, An O(n logn) Unidirectional algorithmfor the circular extrema problem, ACM Trans. Prog.

Lang. Sys., 4 (1982), pp. 758-762.

Downloaded 07/23/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php